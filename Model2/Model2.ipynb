{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2's Implementation: Using VGG 19 CNN Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialise and import libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, Input, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Reshape, MaxPooling2D,  MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.backend import int_shape\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!!! PLEASE SET YOUR WORKING DIRECTORY !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET UP HERE CHANGE THE VALUE TO YOUR FILE DIRECTORY\n",
    "#\n",
    "os.chdir('C:/Users/YOUR_USER/Documents/Colourising_Photos/')\n",
    "\n",
    "#Setting up path for data\n",
    "pathColor = os.getcwd()+\"/Data/colour/\"\n",
    "pathNb = os.getcwd()+\"/Data/black/\"\n",
    "\n",
    "#Set resolution (Current model trained for 256x256)\n",
    "width, height = (256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(include_top=False, weights='imagenet' ,input_tensor=None,  pooling=None, input_shape=(width,height,3), classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VGG19, set up our input layers and output layers, and fill the middle with VGG19 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input, take 256x256 photographs, this can be changed at a later date.\n",
    "inputs = Input(name='Model2_Input', shape=(256,256,1)  )\n",
    "x = Conv2D(filters=3,kernel_size=3, activation='relu',padding='same')(inputs)\n",
    "\n",
    "#Input part of the VGG19 model, not all layers.\n",
    "for lyr in vgg19.layers[:-13]:\n",
    "    x = lyr(x)\n",
    "    x.trainable=False\n",
    "\n",
    "#Perform two transpose conv's for 128x128,128, and 256x256,3 shapes\n",
    "x = Conv2DTranspose(kernel_size=3,activation='relu',strides = 2 , padding='same',filters=128)(x)\n",
    "x = Conv2DTranspose(kernel_size=3,activation='relu',strides = 2 , padding='same',filters=3)(x)\n",
    "\n",
    "#finish the model\n",
    "model = Model(inputs, x, name='model2')\n",
    "#Compile using MSE for loss, and adam optimiser\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create holders for training data and its true coloured version\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "#Open file and read all photos that are training data\n",
    "file = open(os.getcwd()+\"/Data/train.txt\")\n",
    "fileTrainingData = file.readlines()\n",
    "file.close()\n",
    "\n",
    "\n",
    "for f in fileTrainingData:\n",
    "    Ytrain.append( np.load(pathColor + f[:-1]))\n",
    "    Xtrain.append( np.load(pathNb + f[:-1]))\n",
    "\n",
    "# Flatten the data and then reshape it to be (-1,w,h,1)\n",
    "Xtrain = np.asarray(Xtrain).flatten()\n",
    "Xtrain = Xtrain.reshape(-1,width,height,1)\n",
    "Ytrain = np.asarray(Ytrain).flatten()\n",
    "Ytrain = Ytrain.reshape((-1,width,height,3))\n",
    "    \n",
    "#Loading test data\n",
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "file = open(os.getcwd()+\"/Data/test.txt\")\n",
    "fileTestData = file.readlines()\n",
    "file.close()\n",
    "\n",
    "for f in fileTestData:\n",
    "    Ytest.append( np.load(pathColor + f[:-1]))\n",
    "    Xtest.append( np.load(pathNb + f[:-1]))\n",
    "\n",
    "# Flatten the data and then reshape it to be (-1,w,h,1)\n",
    "Xtest = np.asarray(Xtest).flatten()\n",
    "Xtest = Xtest.reshape(-1,width,height,1)\n",
    "Ytest = np.asarray(Ytest).flatten()\n",
    "Ytest = Ytest.reshape((-1,width,height,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 20\n",
    "batch = 22\n",
    "start = 0\n",
    "end = 1000\n",
    "\n",
    "for current in range(start,end,step):\n",
    "    \n",
    "    \n",
    "    model.fit(Xtrain, Ytrain, batch_size=batch, validation_data=(Xtest,Ytest), initial_epoch = current, epochs = current+step)\n",
    "    \n",
    "    #Create file to dump output to\n",
    "    os.mkdir(''+os.getcwd()+'/outputs/Model2/Epoch{}'.format(current + step))\n",
    "    os.mkdir(''+os.getcwd()+'/outputs/Model2/Epoch{}/test'.format(current + step))\n",
    "    os.mkdir(''+os.getcwd()+'/outputs/Model2/Epoch{}/train'.format(current + step))\n",
    " \n",
    "    # Predict\n",
    "    output = model.predict(Xtrain[:])\n",
    "    #Now return the values from 0->1 to 0->255\n",
    "    output *= 255\n",
    "    #Convert from f_32 -> u_int8\n",
    "    output = output.astype('uint8')\n",
    "    #save train images\n",
    "    photo_num = 1\n",
    "    for img in output:\n",
    "        output = Image.fromarray(img)\n",
    "        output.save(''+os.getcwd()+'/outputs/Model2/Epoch{}/train/ouput{}.png'.format(current + step,photo_num))\n",
    "        photo_num += 1\n",
    "        \n",
    "    # Predict\n",
    "    output = model.predict(Xtest[:])\n",
    "    #Now return the values from 0->1 to 0->255\n",
    "    output *= 255\n",
    "    #Convert from f_32 -> u_int8\n",
    "    output = res.astype('uint8')\n",
    "    #Save test images\n",
    "    photo_num = 1\n",
    "    for img in output:\n",
    "        output = Image.fromarray(img)\n",
    "        output.save(''+os.getcwd()+'/outputs/Model2/Epoch{}/test/ouput{}.png'.format(current + step,photo_num))\n",
    "        photo_num += 1    \n",
    "        \n",
    "    #Save model\n",
    "    model.save( \"\"+os.getcwd()+\"/outputs/Model2/Epoch{}/model2_{}.h5\".format(current + step,current + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
